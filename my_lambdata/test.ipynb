{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Test Notebook for pip installing our helper functions to use in a notebook environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pip install the helper functions from pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Looking in indexes: https://test.pypi.org/simple/\nRequirement already satisfied: lambdata-mtoce==1.0.1 in c:\\users\\mike\\.virtualenvs\\lambdata-mtoce-ohc_ymc4\\lib\\site-packages (1.0.1)\n"
    }
   ],
   "source": [
    "!pip install -i https://test.pypi.org/simple/ lambdata-mtoce==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our functions from files within directory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import split_date, add_column, state_abbrev, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our csv from url\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mtoce/Build2-Project/master/astros_bangs_20200127.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dtype('O')"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# check dtype of column\n",
    "df['game_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run split_date function on df and column\n",
    "new_df = split_date.convert_split_dates(df, 'game_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dtype('<M8[ns]')"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "new_df['game_date'].dtype\n",
    "#print(new_df['game_date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       2017\n1       2017\n2       2017\n3       2017\n4       2017\n        ... \n8269    2017\n8270    2017\n8271    2017\n8272    2017\n8273    2017\nName: date_year, Length: 8274, dtype: int64"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# check new column\n",
    "new_df['date_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run add_column function and check new column\n",
    "df_with_new_col = add_column.add_column(new_df, new_df['date_year'].to_list(), 'year_created_from_fnct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       2017\n1       2017\n2       2017\n3       2017\n4       2017\n        ... \n8269    2017\n8270    2017\n8271    2017\n8272    2017\n8273    2017\nName: year_created_from_fnct, Length: 8274, dtype: int64"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_with_new_col['year_created_from_fnct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "game_id                           object\ngame_pk                            int64\ngame_date                 datetime64[ns]\nopponent                          object\nfinal_away_runs                    int64\nfinal_home_runs                    int64\ninning                             int64\ntop_bottom                        object\nbatter                            object\nat_bat_event                      object\npitch_type_code                   object\npitch_category                    object\nhas_bangs                         object\nbangs                             object\ncall_code                         object\ndescription                       object\non_1b                             object\non_2b                             object\non_3b                             object\nyoutube_id                        object\npitch_youtube_seconds              int64\nyoutube_url                       object\npitch_datetime                    object\ngame_pitch_id                     object\nevent_number                       int64\npitch_playid                      object\natbat_playid                      object\naway_team_id                       int64\nhome_team_id                       int64\ndate_year                          int64\ndate_month                         int64\ndate_day                           int64\ndate_hour                          int64\nyear_created_from_fnct             int64\ndtype: object"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # my_lambdata/confusion_matrix\n",
    "\n",
    "# # Object is a confusion matrix that we can run methods on (precision, recall, f1score, etc)\n",
    "# # import sklearn.confusion_matrix\n",
    "# # y_actual = [2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2]\n",
    "# # y_predicted = [0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2]\n",
    "\n",
    "# class c_matrix():\n",
    "#     # define initialize function for class\n",
    "#     def __init__(self, y_true, y_pred):\n",
    "#         self.y_true = y_true\n",
    "#         self.y_pred = y_pred\n",
    "#     # define function of function that creates the main array we will use for the rest of our class.methods()\n",
    "#     def confusion_matrix(self, y_true, y_pred):\n",
    "#         '''\n",
    "#         This docstring's creator and owner: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix\n",
    "\n",
    "#         Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "#         By definition a confusion matrix **C** is such that **C_{ij}** is equal to the number of observations known to be \n",
    "#         in group *i* and predicted to be in group *j*.\n",
    "\n",
    "#         Thus in binary classification, the count of true negatives is **C_{0,0}**, \n",
    "#         false negatives is **C_{1,0}**, true positives is **C_{1,1}** and false positives is **C_{0,1}**.\n",
    "\n",
    "#         Parameters:\n",
    "#             y_true: array-like of shape (n_samples,)\n",
    "#             Ground truth (correct) target values.\n",
    "\n",
    "#             y_pred: array-like of shape (n_samples,)\n",
    "#             Estimated targets as returned by a classifier.\n",
    "\n",
    "#             labels: array-like of shape (n_classes), default=None\n",
    "#             List of labels to index the matrix. This may be used to reorder or select a subset of labels. If None is given, those \n",
    "#             that appear at least once in y_true or y_pred are used in sorted order.\n",
    "\n",
    "#             sample_weight: array-like of shape (n_samples,), default=None\n",
    "#             Sample weights.\n",
    "\n",
    "#             normalize{‘true’, ‘pred’, ‘all’}, default=None\n",
    "#             Normalizes confusion matrix over the true (rows), predicted (columns) conditions or all the population. If None, confusion matrix will not be normalized.\n",
    "\n",
    "#         Returns:\n",
    "#         C: ndarray of shape (n_classes, n_classes)\n",
    "#         Confusion matrix.\n",
    "#         '''\n",
    "#         # defines X, the shape of true_label_array\n",
    "#         X = len(np.unique(y_true)) # Number of classes \n",
    "#         # creates zeroes array with shape length X above\n",
    "#         result = np.zeros((X, X))\n",
    "#         # creates labels list with unique values of true_label_array\n",
    "#         labels = np.unique(y_true)\n",
    "#         # using list comprehension to create a columns_list from labels\n",
    "#         columns = [f'Predicted {label}' for label in labels]\n",
    "#         # using list comp. to create an index_list from labels\n",
    "#         index = [f'Actual {label}' for label in labels]\n",
    "#         # create the confusion matrix array by indexing into the arrays\n",
    "#         for i in range(len(y_true)):\n",
    "#             result[y_true[i]][y_pred[i]] += 1\n",
    "#         # change type of result to a DF\n",
    "#         result = pd.DataFrame((result), index=index, columns=columns)\n",
    "\n",
    "#         return result\n",
    "\n",
    "#     if __name__ == '__main__':\n",
    "#         y_actual = [2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2]\n",
    "#         y_predicted = [0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2]\n",
    "#         cm = c_matrix(y_true=y_actual, y_pred=y_predicted).confusion_matrix(y_true=y_actual, y_pred=y_predicted)\n",
    "#         print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = [2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2]\n",
    "y_predicted = [0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2]\n",
    "\n",
    "# c_matrix(y_true=y_actual, y_pred=y_predicted).confusion_matrix(y_true=y_actual, y_pred=y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def labels(self):\n",
    "    #     labels = np.unique(y_true)\n",
    "    #     return labels\n",
    "    # def recall():\n",
    "    #     '''\n",
    "    #     The true positive / (true positive + false negative) values of a confusion matrix\n",
    "    #     '''\n",
    "    #     tp = \n",
    "    #     r = \n",
    "    #     return \n",
    "    # def precision():\n",
    "\n",
    "    #     return\n",
    "    # def f1():\n",
    "\n",
    "    #     return \n",
    "    # def normalize():\n",
    "\n",
    "    #     return \n",
    "    # def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          Predicted 0  Predicted 1  Predicted 2\nActual 0          3.0          0.0          0.0\nActual 1          0.0          1.0          2.0\nActual 2          2.0          1.0          3.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted 0</th>\n      <th>Predicted 1</th>\n      <th>Predicted 2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Actual 0</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Actual 1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>Actual 2</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from cm import c_matrix\n",
    "\n",
    "c_matrix(y_true=y_actual, y_pred=y_predicted).confusion_matrix(y_true=y_actual, y_pred=y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}